# VITA mm_vision_tower Initialization Documentation

This document explains how the `mm_vision_tower` is initialized in the VITA model, covering all the different initialization paths and scenarios.

## üéØ Overview

The `mm_vision_tower` (multimodal vision tower) is the vision encoder component of the VITA model. It can be initialized in several different ways depending on the model loading scenario and configuration.

## üìã Initialization Paths

### **Path 1: Direct Model Loading (Most Common)**

When loading a pretrained VITA model directly (like in the demo script):

#### **1. Model Loading**
**File**: `/home/tuannv/vlaa/3thrdparties/VITA/vita/model/builder.py:205-207`
```python
# builder.py:205-207
elif model_type == "qwen2p5_instruct":
    print(f'Loading Qwen2.5-7B-Instruct model...\n-\n{model_path}\n----------')
    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)
    model = VITAQwen2ForCausalLM.from_pretrained(
        model_path, low_cpu_mem_usage=True, **kwargs
    )
```

#### **2. VITAMetaModel Initialization**
**File**: `/home/tuannv/vlaa/3thrdparties/VITA/vita/model/vita_arch.py:17-23`
```python
# vita_arch.py:17-23
if hasattr(config, "mm_vision_tower"):
    self.vision_tower = build_vision_tower(
        config, delay_load=False#not getattr(config, "continuous_training", False)
    )
    if getattr(config, "continuous_training", False):
        config.continuous_training = False
    self.mm_projector = build_vision_projector(config)
```

**Context**: The `mm_vision_tower` is initialized during `VITAMetaModel.__init__()` if the config contains the `mm_vision_tower` attribute.

#### **3. Vision Tower Builder**
**File**: `/home/tuannv/vlaa/3thrdparties/VITA/vita/model/multimodal_encoder/builder.py:14-43`
```python
# builder.py:14-43
def build_vision_tower(vision_tower_cfg, **kwargs):
    vision_tower = getattr(
        vision_tower_cfg, "mm_vision_tower", getattr(vision_tower_cfg, "vision_tower", None)
    )
    use_s2 = getattr(vision_tower_cfg, "use_s2", False)

    if "sig" in vision_tower.lower():
        if use_s2:
            return SiglipVisionTowerS2(vision_tower, args=vision_tower_cfg, **kwargs)
        else:
            return SiglipVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)
    elif "eva" in vision_tower.lower():
        if use_s2:
            raise ValueError(f"Currently not supporting S2 for EVA-CLIP")
        else:
            return EvaClipVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)

    elif "clip" in vision_tower.lower():
        if use_s2:
            raise ValueError(f"Currently not supporting S2 for CLIP")
        else:
            return CLIPVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)
    elif "internvit" in vision_tower.lower():
        if use_s2:
            raise ValueError(f"Currently not supporting S2 for InternViT")
        else:
            return InternViTVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)

    else:
        raise ValueError(f"Unknown vision tower: {vision_tower}")
```

**Context**: The builder determines which vision tower implementation to create based on the vision tower name in the config.

### **Path 2: Base Model + Projector Loading**

When loading from a base model with separate projector weights:

#### **1. Base Model Loading**
**File**: `/home/tuannv/vlaa/3thrdparties/VITA/vita/model/builder.py:104-123`
```python
# builder.py:104-123
elif model_base is not None:
    # this may be mm projector only
    print("Loading VITA from base model...")

    cfg_pretrained = AutoConfig.from_pretrained(model_path)
    if model_type == "mixtral-8x7b":
        tokenizer = AutoTokenizer.from_pretrained(model_base, use_fast=True)
        model = VITAMixtralForCausalLM.from_pretrained(
            model_base, low_cpu_mem_usage=True, **kwargs
        )

        # load vision encoder
        from types import SimpleNamespace
        model_args = {
            "vision_tower": f"{GLOBAL_WEIGHTS_PATH}/InternViT-300M-448px",
            "pretrain_mm_mlp_adapter": None,
            "mm_projector_type": "mlp2x_gelu",
        }
        model_args = SimpleNamespace(**model_args)
        model.get_model().initialize_vision_modules(model_args=model_args)
```

**Context**: When `model_base` is provided, the vision modules are initialized using `initialize_vision_modules()`.

#### **2. Vision Modules Initialization**
**File**: `/home/tuannv/vlaa/3thrdparties/VITA/vita/model/vita_arch.py:38-69`
```python
# vita_arch.py:38-69
def initialize_vision_modules(self, model_args):
    vision_tower = model_args.vision_tower

    pretrain_mm_mlp_adapter = model_args.pretrain_mm_mlp_adapter

    self.config.mm_vision_tower = vision_tower

    if self.get_vision_tower() is None:
        vision_tower = build_vision_tower(model_args)
        self.vision_tower = vision_tower
    else:
        vision_tower = self.vision_tower
        #vision_tower.load_model()

    self.config.use_mm_proj = True
    self.config.mm_projector_type = getattr(model_args, "mm_projector_type")
    self.config.mm_hidden_size = vision_tower.hidden_size

    if getattr(self, "mm_projector", None) is None:
        self.mm_projector = build_vision_projector(self.config)
    else:
        # In case it is frozen by LoRA
        for p in self.mm_projector.parameters():
            p.requires_grad = True

    if pretrain_mm_mlp_adapter is not None:
        mm_projector_weights = torch.load(pretrain_mm_mlp_adapter, map_location="cpu")

        def get_w(weights, keyword):
            return {k.split(keyword + ".")[1]: v for k, v in weights.items() if keyword in k}

        self.mm_projector.load_state_dict(get_w(mm_projector_weights, "mm_projector"))
```

**Context**: This method sets up the vision tower and projector, loading pretrained weights if available.

### **Path 3: Training Script Initialization**

During training, the vision modules are initialized explicitly:

#### **1. Training Script Call**
**File**: `/home/tuannv/vlaa/3thrdparties/VITA/vita/train/train.py:352`
```python
# train.py:352
model.get_model().initialize_vision_modules(model_args=model_args)
```

#### **2. Model Arguments**
**File**: `/home/tuannv/vlaa/3thrdparties/VITA/vita/train/train.py:55`
```python
# train.py:55
vision_tower: Optional[str] = field(default=None)
```

**Context**: The training script passes vision tower configuration through `ModelArguments`.

## üîß Configuration Sources

### **1. Model Config File**
The `mm_vision_tower` can be set in the model's configuration file (e.g., `config.json`):
```json
{
  "mm_vision_tower": "/path/to/InternViT-300M-448px",
  "mm_projector_type": "mlp2x_gelu",
  "mm_hidden_size": 1024
}
```

### **2. Command Line Arguments**
During training, the vision tower path can be specified via command line:
```bash
python train.py --vision_tower /path/to/InternViT-300M-448px
```

### **3. Hardcoded Paths**
In some cases, the vision tower path is hardcoded in the builder:
```python
# builder.py:118
"vision_tower": f"{GLOBAL_WEIGHTS_PATH}/InternViT-300M-448px"
```

## üèóÔ∏è Vision Tower Types

The `build_vision_tower` function supports multiple vision tower implementations:

### **1. InternViT (Default for VITA-1.5)**
```python
elif "internvit" in vision_tower.lower():
    return InternViTVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)
```

### **2. SigLIP**
```python
if "sig" in vision_tower.lower():
    if use_s2:
        return SiglipVisionTowerS2(vision_tower, args=vision_tower_cfg, **kwargs)
    else:
        return SiglipVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)
```

### **3. CLIP**
```python
elif "clip" in vision_tower.lower():
    return CLIPVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)
```

### **4. EVA-CLIP**
```python
elif "eva" in vision_tower.lower():
    return EvaClipVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)
```

## üîÑ Initialization Flow

### **Complete Flow for Demo Script**
```
1. demo.sh calls video_audio_demo.py
2. video_audio_demo.py calls load_pretrained_model()
3. load_pretrained_model() loads VITAQwen2ForCausalLM.from_pretrained()
4. VITAQwen2ForCausalLM.__init__() creates VITAQwen2Model
5. VITAQwen2Model.__init__() calls VITAMetaModel.__init__()
6. VITAMetaModel.__init__() checks hasattr(config, "mm_vision_tower")
7. If True, calls build_vision_tower(config, delay_load=False)
8. build_vision_tower() determines vision tower type and creates instance
9. InternViTVisionTower.__init__() initializes the vision encoder
10. InternViTVisionTower.load_model() loads the actual InternViT model
```

### **Key Initialization Steps**

#### **1. Config Check**
```python
if hasattr(config, "mm_vision_tower"):
    # Initialize vision tower
```

#### **2. Vision Tower Creation**
```python
self.vision_tower = build_vision_tower(config, delay_load=False)
```

#### **3. Projector Creation**
```python
self.mm_projector = build_vision_projector(config)
```

#### **4. Model Loading**
```python
def load_model(self):
    self.image_processor = CLIPImageProcessor.from_pretrained(self.vision_tower_name)
    self.vision_tower = InternVisionModel.from_pretrained(
        self.vision_tower_name, trust_remote_code=True
    )
    self.vision_tower.requires_grad_(False)
    self.is_loaded = True
```

## üéØ Key Configuration Attributes

### **1. mm_vision_tower**
- **Type**: String (path to vision tower)
- **Purpose**: Specifies which vision encoder to use
- **Example**: `"/path/to/InternViT-300M-448px"`

### **2. mm_projector_type**
- **Type**: String
- **Purpose**: Specifies the projector architecture
- **Default**: `"mlp2x_gelu"`

### **3. mm_hidden_size**
- **Type**: Integer
- **Purpose**: Hidden dimension of the vision tower
- **Set automatically**: Based on vision tower's hidden size

### **4. use_mm_proj**
- **Type**: Boolean
- **Purpose**: Whether to use multimodal projector
- **Default**: `True`

## üîç Lazy Loading Support

The vision tower supports lazy loading through the `delay_load` parameter:

### **Immediate Loading**
```python
# delay_load=False (default)
self.vision_tower = build_vision_tower(config, delay_load=False)
```

### **Lazy Loading**
```python
# delay_load=True
self.vision_tower = build_vision_tower(config, delay_load=True)
# Model is loaded later when needed
```

## üìä Memory and Performance

### **Memory Usage**
- **Vision Tower**: ~300M parameters (InternViT-300M)
- **Image Processor**: Minimal memory footprint
- **Projector**: Depends on `mm_projector_type`

### **Loading Time**
- **Immediate Loading**: Slower startup, faster inference
- **Lazy Loading**: Faster startup, slower first inference

## üöÄ Best Practices

### **1. Configuration Management**
- Set `mm_vision_tower` in model config for consistency
- Use absolute paths for vision tower locations
- Specify `mm_projector_type` explicitly

### **2. Memory Optimization**
- Use `delay_load=True` for memory-constrained environments
- Set appropriate device mapping for multi-GPU setups
- Consider quantization for deployment

### **3. Training Considerations**
- Initialize vision modules before training
- Set appropriate freeze/unfreeze parameters
- Load pretrained projector weights when available

## üìù Summary

The `mm_vision_tower` initialization in VITA follows a flexible pattern that supports multiple loading scenarios:

1. **Direct Loading**: From pretrained model config
2. **Base Model Loading**: With separate projector weights
3. **Training Initialization**: With explicit configuration

The system uses a builder pattern to create the appropriate vision tower implementation based on the configuration, with support for lazy loading and multiple vision encoder types. The initialization process ensures that both the vision tower and multimodal projector are properly set up for the specific use case.
